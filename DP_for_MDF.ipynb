{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DP for MDF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/paxx13/gym/blob/master/DP_for_MDF.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "EUndq7QGj-lk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "this notebook shows dynamic programming techniques to solve a markov devision process(MDP)"
      ]
    },
    {
      "metadata": {
        "id": "7f_Ff9dcJmTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pevBr_l8j1Mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import (absolute_import, division, print_function,\n",
        "unicode_literals)\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFPNkqolmoty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "env.reset()\n",
        "env.render()\n",
        "'''\n",
        "SFFF       (S: starting point, safe)\n",
        "FHFH       (F: frozen surface, safe)\n",
        "FFFH       (H: hole, fall to your doom)\n",
        "HFFG       (G: goal, where the frisbee is located)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zqcF-xc60vzQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "random search"
      ]
    },
    {
      "metadata": {
        "id": "26oa_3BWnaPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_random_policy(env):\n",
        "  observation = env.reset()\n",
        "  total_reward = 0\n",
        "  num_steps = 0\n",
        "  for i in range(100):\n",
        "    env.render()\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "\n",
        "    total_reward += reward\n",
        "    num_steps += 1\n",
        "\n",
        "    if done:\n",
        "      print('===========  policy done ==========')\n",
        "      break\n",
        "      \n",
        "  return num_steps, total_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84gtZ0vn_-j1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_params = None\n",
        "best_reward = 0\n",
        "\n",
        "for _ in range(1000):\n",
        "  steps, reward  = run_random_policy(env)\n",
        "  if reward > best_reward:\n",
        "    best_reward = reward\n",
        "    best_steps = steps\n",
        "    if reward == 1:\n",
        "      break\n",
        "      \n",
        "print('best reward: ', best_reward)\n",
        "print('number of steps taken: ', best_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}